{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import random\n",
    "import deepdish as dd\n",
    "import fnmatch, numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "import tqdm\n",
    "import string\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = '/home/jvidyala/final_data/'\n",
    "GENRE_DIR = HOME_DIR + 'file_genres/'\n",
    "DATA_DIR = '/home/jvidyala/data/original_data/'\n",
    "AFV_DIR = HOME_DIR + 'avg_feat_vectors/'\n",
    "TRAIN_DATA = HOME_DIR + 'mf_train_data/'\n",
    "TEST_DATA = HOME_DIR + 'mf_test_data/'\n",
    "WEIGHTS_DIR = HOME_DIR + 'model_weights/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data extraction using MGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extraction():\n",
    "    dataset = pd.read_csv(\"/home/jvidyala/msd-genre-dataset.txt\",sep=\",\",skiprows=9)\n",
    "    \n",
    "    \n",
    "    file_choices = dataset['track_id'].values\n",
    "\n",
    "    mfcc_coeffs = {}\n",
    "    avg_feature_vector = {}\n",
    "    for file in tqdm.tqdm(file_choices):\n",
    "        file_load = dd.io.load(DATA_DIR + file[2] + '/' + file[3] + '/' + file[4] + '/' + file + '.h5')\n",
    "        temp_load = file_load['analysis']['segments_timbre']\n",
    "        mfcc_coeffs[file] = temp_load\n",
    "        temp = []\n",
    "        try:\n",
    "            for j in range(12):\n",
    "                feature_set = [(mfcc_coeffs[file][j]) for i in range(mfcc_coeffs[file].shape[0])]\n",
    "                avg_feature = np.mean(np.array(feature_set))\n",
    "                temp.append(avg_feature)\n",
    "            avg_feature_vector[file]=temp\n",
    "        except IndexError as e:\n",
    "            print(file)\n",
    "            \n",
    "    dd.io.save(HOME_DIR+'afv_mgd.h5',avg_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train GMM using defined balanced train set\n",
    "def genre_GMM(train_set):\n",
    "    gmm = GaussianMixture(n_components=10,covariance_type='full').fit(train_set)    \n",
    "    dd.io.save(HOME_DIR + 'gmm.h5',gmm)\n",
    "\n",
    "#Song to song mhl distance\n",
    "def mahalanobis_point(x,y,cov):\n",
    "    cov_inverse = np.linalg.inv(cov)\n",
    "    return (np.matmul(np.matmul(x-y,cov_inverse),np.transpose(x-y))**0.5)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_track_avg(file):\n",
    "    temp_load = dd.io.load(DATA_DIR + file[2] + '/' + file[3] + '/' + file[4] + '/' + file + '.h5')['analysis']['segments_timbre']\n",
    "    avg_vector,temp = {},[]\n",
    "    for j in range(12):\n",
    "                feature_set = [(temp_load[j]) for i in range(temp_load.shape[0])]\n",
    "                avg_feature = np.mean(np.array(feature_set))\n",
    "                temp.append(avg_feature)\n",
    "    #avg_vector[file]=temp\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_clusters(gmm,track_id):\n",
    "    x = calc_track_avg(track_id)\n",
    "    \n",
    "    #     afv = dd.io.load(HOME_DIR + 'afv_mgd.h5')\n",
    "    #     x = afv[track_id]\n",
    "    probs = gmm.predict_proba(np.array(x).reshape(1,-1))\n",
    "    \n",
    "    lprobs = sorted(probs.tolist()[0],reverse=True)\n",
    "    temp = probs.tolist()[0]\n",
    "    vals = lprobs[:3]\n",
    "    closest_clusters = [temp.index(val) for val in vals]\n",
    "    \n",
    "    return closest_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_cluster_assignment(gmm):\n",
    "    track_clusters = {i:[] for i in range(10)}\n",
    "    afv = dd.io.load(HOME_DIR + 'afv_mgd.h5')\n",
    "    for track,x in tqdm.tqdm(afv.items()):\n",
    "        probs = gmm.predict_proba(np.array(x).reshape(1,-1))\n",
    "        lprobs = sorted(probs.tolist()[0],reverse=True)\n",
    "        temp = probs.tolist()[0]\n",
    "        vals = lprobs[:3]\n",
    "        clusters = [temp.index(val) for val in vals]\n",
    "        \n",
    "        for cluster in clusters:\n",
    "            track_clusters[cluster].append(track)\n",
    "    dd.io.save(HOME_DIR + 'track_clusters.h5',track_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equal representation from each genre\n",
    "def gmm_train_set():\n",
    "    dataset = pd.read_csv(\"/home/jvidyala/msd-genre-dataset.txt\",sep=\",\",skiprows=9)\n",
    "\n",
    "    starting_indices = [0]\n",
    "    for idx in range(1,len(dataset['%genre'].values)):\n",
    "        if (dataset['%genre'].values)[idx-1]!=(dataset['%genre'].values)[idx]:\n",
    "            starting_indices.append(idx)\n",
    "    \n",
    "    file_choices = []\n",
    "    for i in range(len(starting_indices)):\n",
    "        file_choices += (dataset['track_id'].values)[starting_indices[i]:starting_indices[i]+434].tolist()\n",
    "     \n",
    "    train_set = []\n",
    "    afv_mgd = dd.io.load(HOME_DIR + 'afv_mgd.h5')    \n",
    "\n",
    "    for file in file_choices:\n",
    "        try:\n",
    "            train_set.append(afv_mgd[file])\n",
    "        except KeyError:\n",
    "            print(file)\n",
    "\n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_predictions(track_id):\n",
    "    if not HOME_DIR+'afv_mgd.h5':\n",
    "        data_extraction()\n",
    "    if not HOME_DIR+'track_clusters.h5':\n",
    "        track_cluster_assignment()\n",
    "    if not HOME_DIR+'gmm.h5':\n",
    "        train_set = gmm_train_set()\n",
    "        genre_GMM(train_set)\n",
    "        \n",
    "    gmm = dd.io.load(HOME_DIR + 'gmm.h5')\n",
    "    track_clusters = dd.io.load(HOME_DIR + 'track_clusters.h5')\n",
    "    \n",
    "    #kclusters = indices of highest prob gmm components  \n",
    "    kclusters = closest_clusters(gmm,track_id)\n",
    "    song_set = {}\n",
    "    for i in kclusters:\n",
    "        song_set[i] = track_clusters[i] \n",
    "        \n",
    "    #song_set contains all acoustically similar songs    \n",
    "    \n",
    "    distances = mahalanobis_dist_set(gmm,song_set,track_id)\n",
    "    \n",
    "    return sorted(distances,key=distances.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_dist_set(gmm,song_set,track_id):\n",
    "    x = np.array(calc_track_avg(track_id))\n",
    "    afv_mgd = dd.io.load(HOME_DIR + 'afv_mgd.h5')\n",
    "    distances = {}\n",
    "    for cluster_id in song_set.keys():\n",
    "        for track in song_set[cluster_id]:\n",
    "            \n",
    "            #Song to song Mhl dist calc\n",
    "            cov = gmm.covariances_[cluster_id]\n",
    "            y = np.array(afv_mgd[track])\n",
    "            cov_inverse = np.linalg.inv(cov) \n",
    "    \n",
    "            dist = np.matmul(np.matmul(x-y,cov_inverse),np.transpose(x-y))**0.5\n",
    "            \n",
    "            distances[track] = dist\n",
    "\n",
    "    return distances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
