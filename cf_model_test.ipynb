{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "import os, math\n",
    "import keras.backend as K\n",
    "from numpy import random\n",
    "from __future__ import division\n",
    "from sklearn import dummy, metrics, cross_validation, ensemble\n",
    "from keras.layers import Input, Embedding, Flatten, Dropout, Conv2D, merge, normalization, MaxPooling1D,Dense, Dot, Concatenate, Merge, Conv1D, Add,add\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from IPython.display import SVG\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "\n",
    "import keras\n",
    "import deepdish as dd\n",
    "from read_activations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_songid = dd.io.load('/home/jvidyala/model_sample_data/a_songid.h5')\n",
    "b_songid = dd.io.load('/home/jvidyala/model_sample_data/b_songid.h5')\n",
    "a_userid = dd.io.load('/home/jvidyala/model_sample_data/a_userid.h5')\n",
    "b_userid = dd.io.load('/home/jvidyala/model_sample_data/b_userid.h5')\n",
    "a_y = dd.io.load('/home/jvidyala/model_sample_data/a_y.h5')\n",
    "b_y = dd.io.load('/home/jvidyala/model_sample_data/b_y.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 1019318\n",
    "n_songs = 384546"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic MF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_input = Input(shape=[1])\n",
    "song_embedding = Flatten()(Embedding(n_songs+1, 16)(song_input))\n",
    "song_vec = (song_embedding)\n",
    "\n",
    "user_input = Input(shape=[1])\n",
    "user_embedding = Flatten()(Embedding(n_users+1, 16)(user_input))\n",
    "user_vec = (user_embedding)\n",
    "    \n",
    "input_vecs = merge([song_vec,user_vec],mode='dot')    \n",
    "x = Dense(128, activation='relu')(input_vecs)\n",
    "x = Dense(128, activation='relu')(input_vecs)\n",
    "\n",
    "y = Dense(1)(x)\n",
    "model = Model(inputs=[song_input,user_input],outputs=y)\n",
    "model.compile(loss='mse',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47992 samples, validate on 2020 samples\n",
      "Epoch 1/10\n",
      "47992/47992 [==============================] - 41s 856us/step - loss: 105.4570 - val_loss: 46.6448\n",
      "Epoch 2/10\n",
      "47992/47992 [==============================] - 21s 432us/step - loss: 102.0435 - val_loss: 47.5735\n",
      "Epoch 3/10\n",
      "47992/47992 [==============================] - 21s 432us/step - loss: 94.4999 - val_loss: 49.2295\n",
      "Epoch 4/10\n",
      "47992/47992 [==============================] - 21s 431us/step - loss: 87.5193 - val_loss: 50.5565\n",
      "Epoch 5/10\n",
      "47992/47992 [==============================] - 21s 432us/step - loss: 82.2357 - val_loss: 52.4793\n",
      "Epoch 6/10\n",
      "47992/47992 [==============================] - 21s 431us/step - loss: 78.6655 - val_loss: 52.5632\n",
      "Epoch 7/10\n",
      "47992/47992 [==============================] - 21s 433us/step - loss: 75.7201 - val_loss: 53.0329\n",
      "Epoch 8/10\n",
      "47992/47992 [==============================] - 21s 433us/step - loss: 72.9290 - val_loss: 53.3300\n",
      "Epoch 9/10\n",
      "47992/47992 [==============================] - 21s 434us/step - loss: 70.5033 - val_loss: 52.9650\n",
      "Epoch 10/10\n",
      "47992/47992 [==============================] - 21s 434us/step - loss: 68.2650 - val_loss: 53.2092\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([a_songid,a_userid], a_y,\n",
    "                   epochs = 10,\n",
    "                   validation_data=([b_songid, b_userid], b_y),\n",
    "                   batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_input = Input(shape=[1])\n",
    "song_embedding = Flatten()(Embedding(n_songs+1, 16)(song_input))\n",
    "song_vec = Dropout(0.2)(song_embedding)\n",
    "\n",
    "\n",
    "user_input = Input(shape=[1])\n",
    "user_embedding = Flatten()(Embedding(n_users+1, 16)(user_input))\n",
    "user_vec = Dropout(0.2)(user_embedding)\n",
    "\n",
    "song_bias = Embedding(input_dim=n_songs,output_dim=1,input_length=1)(song_input)\n",
    "user_bias = Embedding(input_dim=n_users,output_dim=1,input_length=1)(user_input)\n",
    "\n",
    "input_vecs = Concatenate()([song_vec,user_vec]) \n",
    "x = add([input_vecs,song_bias,user_bias])\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(input_vecs)\n",
    "\n",
    "y = Dense(1)(x)\n",
    "model = Model(inputs=[song_input,user_input],outputs=y)\n",
    "model.compile(loss='mse',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47992 samples, validate on 2020 samples\n",
      "Epoch 1/10\n",
      "47992/47992 [==============================] - 21s 446us/step - loss: 102.9100 - val_loss: 40.5931\n",
      "Epoch 2/10\n",
      "47992/47992 [==============================] - 21s 440us/step - loss: 98.4402 - val_loss: 38.1002\n",
      "Epoch 3/10\n",
      "47992/47992 [==============================] - 21s 439us/step - loss: 93.7318 - val_loss: 39.3461\n",
      "Epoch 4/10\n",
      "47992/47992 [==============================] - 21s 437us/step - loss: 89.4407 - val_loss: 41.3951\n",
      "Epoch 5/10\n",
      "47992/47992 [==============================] - 21s 438us/step - loss: 85.2411 - val_loss: 45.8071\n",
      "Epoch 6/10\n",
      "47992/47992 [==============================] - 21s 439us/step - loss: 82.3194 - val_loss: 44.4275\n",
      "Epoch 7/10\n",
      "47992/47992 [==============================] - 21s 438us/step - loss: 79.5438 - val_loss: 48.4840\n",
      "Epoch 8/10\n",
      "47992/47992 [==============================] - 21s 439us/step - loss: 77.3144 - val_loss: 50.0199\n",
      "Epoch 9/10\n",
      "47992/47992 [==============================] - 21s 440us/step - loss: 75.8989 - val_loss: 52.8928\n",
      "Epoch 10/10\n",
      "47992/47992 [==============================] - 21s 436us/step - loss: 76.8096 - val_loss: 53.0540\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([a_songid,a_userid], a_y,\n",
    "                   epochs = 10,\n",
    "                   validation_data=([b_songid, b_userid], b_y),\n",
    "                   batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = Input(shape=[1])\n",
    "user_embedding = Flatten()(Embedding(input_dim=n_users+1, output_dim=16)(user_input))\n",
    "user_vec = Dense(16)(user_embedding)\n",
    "user_vec = Dense(16)(user_vec)\n",
    "\n",
    "song_input = Input(shape=[1])\n",
    "song_embedding = Flatten()(Embedding(input_dim=n_songs+1, output_dim=16)(song_input))\n",
    "song_vec = Dense(16)(song_embedding)\n",
    "song_vec = Dense(16)(song_vec)\n",
    "\n",
    "prediction = merge([user_vec,song_vec],mode='dot')\n",
    "prediction = Dense(16)(prediction)\n",
    "prediction = Dense(1)(prediction)\n",
    "\n",
    "model = Model(inputs=[user_input,song_input],outputs=prediction)\n",
    "model.compile(loss='mse',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47992 samples, validate on 2020 samples\n",
      "Epoch 1/10\n",
      "47992/47992 [==============================] - 22s 461us/step - loss: 104.3873 - val_loss: 44.5188\n",
      "Epoch 2/10\n",
      "47992/47992 [==============================] - 22s 449us/step - loss: 100.4317 - val_loss: 44.7838\n",
      "Epoch 3/10\n",
      "47992/47992 [==============================] - 22s 450us/step - loss: 95.1700 - val_loss: 48.0210\n",
      "Epoch 4/10\n",
      "47992/47992 [==============================] - 22s 449us/step - loss: 90.8325 - val_loss: 53.0685\n",
      "Epoch 5/10\n",
      "47992/47992 [==============================] - 22s 451us/step - loss: 86.7563 - val_loss: 57.4254\n",
      "Epoch 6/10\n",
      "47992/47992 [==============================] - 22s 452us/step - loss: 81.4962 - val_loss: 65.2434\n",
      "Epoch 7/10\n",
      "47992/47992 [==============================] - 22s 451us/step - loss: 73.9924 - val_loss: 78.2448\n",
      "Epoch 8/10\n",
      "47992/47992 [==============================] - 22s 452us/step - loss: 62.3539 - val_loss: 95.4498\n",
      "Epoch 9/10\n",
      "47992/47992 [==============================] - 22s 453us/step - loss: 44.9154 - val_loss: 153.2545\n",
      "Epoch 10/10\n",
      "47992/47992 [==============================] - 22s 454us/step - loss: 30.0014 - val_loss: 162.2266\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([a_songid,a_userid], a_y,\n",
    "                   epochs = 10,\n",
    "                   validation_data=([b_songid, b_userid], b_y),\n",
    "                   batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
