{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, deepdish as dd\n",
    "import shutil, csv\n",
    "import random, deepdish as dd, math\n",
    "import fnmatch, numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "import fileinput\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_VECS_FNAME = 'avg_vecs.h5'\n",
    "GENRE_LOOKUP_FNAME = 'genre_lookup.h5'\n",
    "TRAIN_SETS_FNAME = 'train_sets.h5'\n",
    "GMMS_FNAME = 'gmms.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = '/home/jvidyala/'\n",
    "DATA_DIR = '/home/jvidyala/data/original_data/'\n",
    "CLUSTER_DIR = '/home/jvidyala/data/cluster_test/'\n",
    "CLUSTER2_DIR = HOME_DIR+'data/'+'cluster_test2/'\n",
    "SAMPLE_TEST_DIR = CLUSTER2_DIR+'test_data/'\n",
    "\n",
    "os.chdir(CLUSTER2_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global dataset creation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates dictionary with file:avg_vector\n",
    "def calc_avg_coeffs(dir):\n",
    "    mfcc_coeffs = {filename: [] for idx,filename in enumerate(fnmatch.filter(os.listdir(dir),'TR*.h5'))}\n",
    "    avg_feature_vector = {filename: [] for idx,filename in enumerate(fnmatch.filter(os.listdir(dir),'TR*.h5'))}\n",
    "    for file in fnmatch.filter(os.listdir(dir),'TR*.h5'):\n",
    "        try:\n",
    "            temp_load = dd.io.load(file)['analysis']['segments_timbre']\n",
    "            mfcc_coeffs[file] = temp_load\n",
    "            temp = []\n",
    "            for j in range(12):\n",
    "                feature_set = [(mfcc_coeffs[file][j]) for i in range(mfcc_coeffs[file].shape[0])]\n",
    "                avg_feature = np.mean(np.array(feature_set))\n",
    "                temp.append(avg_feature)\n",
    "            avg_feature_vector[file]=temp\n",
    "        except IOError as e:\n",
    "            print(e)\n",
    "    return avg_feature_vector\n",
    "\n",
    "#Creates dictionary of track:genre\n",
    "def genre_lookup(dir):\n",
    "    file_genres = {}\n",
    "    if 'file_genres.h5' not in os.listdir(dir):\n",
    "        for track in fnmatch.filter(os.listdir(dir),'TR*.h5'):\n",
    "            file_genres[track]=dd.io.load(track)['musicbrainz']['artist_mbtags'][0]\n",
    "        dd.io.save('file_genres.h5',file_genres)\n",
    "    else:\n",
    "        file_genres = dd.io.load('file_genres.h5')\n",
    "    return file_genres  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM-related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return GMMs with train sets for each GMM\n",
    "def genre_GMM(avg_feature_vector_set,genre_mappings_set):\n",
    "    gmms = {}\n",
    "    train_sets = {}\n",
    "    for idx,genre in enumerate(set(genre_mappings_set.values())):\n",
    "        train_set = [val for key,val in avg_feature_vector_set.items() if genre_mappings_set[key]==genre]\n",
    "        gmm_genre = GaussianMixture(n_components=1,covariance_type='tied').fit(train_set)\n",
    "        gmms[genre]=(gmm_genre)   \n",
    "        train_sets[genre]=(train_set)\n",
    "        \n",
    "    return gmms,train_sets\n",
    "\n",
    "def mahalanobis(x,mean,cov):\n",
    "    cov_inverse = np.linalg.inv(cov)\n",
    "    return (np.matmul(np.matmul(x-mean,cov_inverse),np.transpose(x-mean))**0.5)[0][0]\n",
    "\n",
    "def mahalanobis_point(x,y,cov,track):\n",
    "    x = x[track]\n",
    "    cov_inverse = np.linalg.inv(cov)\n",
    "    print (np.matmul(np.matmul(x-y,cov_inverse),np.transpose(x-y))**0.5)\n",
    "    \n",
    "def proximity_neighbors(gmms,avg_feature_vector,seed='TRQYNRE128F147C605.h5'):\n",
    "    distances = {}\n",
    "    for genre,gmm in gmms.items():\n",
    "        X = np.array(avg_feature_vector[seed]).reshape(1,-1)\n",
    "        distances[genre]=mahalanobis(X,gmm.means_[0],gmm.covariances_)\n",
    "    return distances\n",
    "\n",
    "def file_move(fname):\n",
    "    fname+='.h5'\n",
    "    shutil.copy(DATA_DIR+'/'+fname[2]+'/'+fname[3]+'/'+fname[4]+'/'+fname,CLUSTER2_DIR+'test_data/') \n",
    "\n",
    "\n",
    "def find_track_from_mfcc(gmms,vector,avg_feature_vector):\n",
    "    for key,val in avg_feature_vector.items():\n",
    "        if np.array_equal(val,vector): \n",
    "            break\n",
    "    file_genres = dd.io.load('file_genres.h5')\n",
    "    genre = file_genres[key]\n",
    "    return genre,key\n",
    "\n",
    "def calc_track_avg(file,dir):\n",
    "    temp_load = dd.io.load(dir+file)['analysis']['segments_timbre']\n",
    "    avg_vector,temp = {},[]\n",
    "    for j in range(12):\n",
    "                feature_set = [(temp_load[j]) for i in range(temp_load.shape[0])]\n",
    "                avg_feature = np.mean(np.array(feature_set))\n",
    "                temp.append(avg_feature)\n",
    "    avg_vector[file]=temp\n",
    "    return avg_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def priority_calc(play_counts,alpha=0.1,offset=10):\n",
    "    y = math.exp(-1*alpha*(play_counts-offset))\n",
    "    return 1/(1+y)\n",
    "    \n",
    "def weighted_randomizer(priorities):\n",
    "    total = sum(list(priorities.values()))\n",
    "    rand = random.uniform(0,total)\n",
    "    for key,val in priorities.items():\n",
    "        rand = rand-val\n",
    "        if rand<0:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial calculations & base file storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_setup(dir):\n",
    "    avg_vectors = calc_avg_coeffs(dir)\n",
    "    file_genres = genre_lookup(dir)\n",
    "    gmms, train_sets = genre_GMM(avg_vectors,file_genres)\n",
    "   \n",
    "    modified_gmms = {}\n",
    "    for key in gmms.keys():\n",
    "        new_key = key.replace(' ','_')\n",
    "        modified_gmms[new_key]=[gmms[key],0,0]\n",
    "\n",
    "    dd.io.save(AVG_VECS_FNAME,avg_vectors)\n",
    "    dd.io.save(GENRE_LOOKUP_FNAME,file_genres)\n",
    "    dd.io.save(TRAIN_SETS_FNAME,train_sets)\n",
    "    dd.io.save(GMMS_FNAME,modified_gmms)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input stream processing from playlist.txt, outputs recommendations per song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendations():\n",
    "#     f = fileinput.input(files=('test.txt'))\n",
    "#     for line in f:\n",
    "#         print(line)\n",
    "#         d = raw_input()\n",
    "    avg_vectors = dd.io.load(AVG_VECS_FNAME)\n",
    "    file_genres = dd.io.save(GENRE_LOOKUP_FNAME)\n",
    "    train_sets = dd.io.save(TRAIN_SETS_FNAME)\n",
    "    gmms = dd.io.save(GMMS_FNAME)\n",
    "    \n",
    "    playlist = [random.choice(fnmatch.filter(os.listdir(CLUSTER2_DIR),'TR*.h5')) for i in range(10)]\n",
    "    for song in playlist:\n",
    "        neighbor_clusters,train_set = closest_clusters(track,gmms,avg_feature_vector,train_sets)\n",
    "        track_avg_vector = calc_track_avg(track,CLUSTER2_DIR)\n",
    "        \n",
    "        #check directory\n",
    "        track_genre = dd.io.load(song+'.h5')['musicbrainz']['artist_mbtags'][0]\n",
    "        \n",
    "        dist = {}\n",
    "        for train_track in train_set:\n",
    "            train_track_genre,train_track_name = find_track_from_mfcc(gmms,train_track,avg_vectors)\n",
    "            dist[train_track_name]=mahalanobis_point(avg_vector,train_track,mms[train_track_genre].covariances_,track)\n",
    "\n",
    "        recs1 = (sorted(dist,key=dist.get)[:10])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "(25, 'Inappropriate ioctl for device')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-fbd55f77ab7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-18b77f2e7223>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeynames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'curses'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfileinput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.sh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'KEY_RIGHT'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/curtsies/input.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_stty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtermios\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtcgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mtty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetcbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtermios\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCSANOW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: (25, 'Inappropriate ioctl for device')"
     ]
    }
   ],
   "source": [
    "os.chdir(CLUSTER2_DIR)\n",
    "initial_setup(CLUSTER2_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
